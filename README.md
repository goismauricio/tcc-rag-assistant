
# TCC RAG Assistant ðŸ§ ðŸ“„

Um assistente de perguntas e respostas sobre documentos PDF usando LLMs com RAG (Retrieval-Augmented Generation).  
Feito como teste com meu TCC, mas funciona com qualquer PDF tÃ©cnico, artigo ou relatÃ³rio.

## ðŸš€ Tecnologias utilizadas

- [Ollama](https://ollama.com/) com LLaMA 3 (ou outro modelo local compatÃ­vel)
- [LangChain](https://www.langchain.com/)
- [ChromaDB](https://www.trychroma.com/)
- [Streamlit](https://streamlit.io/)

## ðŸ’¡ O que o projeto faz

VocÃª fornece um arquivo PDF e pode fazer perguntas em linguagem natural sobre o conteÃºdo.  
O sistema realiza buscas vetoriais (RAG) e responde com base no texto real, citando as fontes (chunks).

## ðŸ“¦ Como rodar localmente

### PrÃ©-requisitos

- Python 3.10+
- [Ollama instalado localmente](https://ollama.com/)
- Modelos baixados no Ollama (ex: `llama3.2 e nomic-embed-text`)
- Instalar dependÃªncias:

```bash
pip install -r requirements.txt
